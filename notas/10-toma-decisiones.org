#+TITLE: EST-46115: Modelación Bayesiana. 
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Toma de decisiones~
#+STARTUP: showall
:REVEAL_PROPERTIES:
#+LANGUAGE: es
#+OPTIONS: num:nil toc:nil timestamp:nil
#+REVEAL_REVEAL_JS_VERSION: 4
#+REVEAL_THEME: night
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Modelación Bayesiana">
#+REVEAL_INIT_OPTIONS: width:1600, height:900, margin:.2
#+REVEAL_EXTRA_CSS: ./mods.css
#+REVEAL_PLUGINS: (notes)
:END:
#+PROPERTY: header-args:R :session toma-decisiones :exports both :results output org :tangle ../rscripts/10-toma-decisiones.R :mkdirp yes :dir ../
#+EXCLUDE_TAGS: toc latex


#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2022 | Toma de decisiones.\\
*Objetivo*: En esta sección conectaremos conceptos que hemos visto durante el curso para toma de decisiones bajo incertidumbre. Anteriormente, introdujimos el concepto de inferencia Bayesiana dentro del marco de teoría de la decisión. Retomaremos ciertos componentes de este marco en el contexto de inferencia y modelado predictivo..\\
*Lectura recomendada*: Sección 9.9 de citep:Martin2021. Capítulo 9 de citep:Gelman2014a. Algunos pasajes de citep:Vehtari2012a. el libro de citet:Gilboaa es una excelente referencia para el modelado de toma de decisiones bajo incertidumbre.  
#+END_NOTES

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(tidyverse)
  library(patchwork)
  library(scales)
  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 2)

  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())
#+end_src


#+begin_src R :exports none :results none
  ## Librerias para modelacion bayesiana
  library(cmdstanr)
  library(posterior)
  library(bayesplot)
#+end_src


* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
- [[#definición-de-un-problema-de-decisión][Definición de un problema de decisión]]
  - [[#contexto-bayesiano][Contexto bayesiano]]
  - [[#caso-enfoque-predictivo][Caso: enfoque predictivo]]
  - [[#caso-enfoque-de-inferencia][Caso: enfoque de inferencia]]
    - [[#pregunta][Pregunta:]]
- [[#análisis-de-decisión][Análisis de decisión]]
  - [[#definición-de-decisiones-y-observaciones][Definición de decisiones y observaciones]]
  - [[#definición-de-estado-de-conocimiento][Definición de estado de conocimiento]]
  - [[#definición-función-de-utilidad][Definición función de utilidad]]
  - [[#cálculo-de-utilidad-esperada][Cálculo de utilidad esperada]]
- [[#funciones-de-utilidad][Funciones de utilidad]]
  - [[#ejemplo-prueba-bechdel][Ejemplo: Prueba Bechdel]]
- [[#decisiones-continuas][Decisiones continuas]]
- [[#referencias][Referencias]]
:END:

* Introducción 

Retomaremos la discusión sobre toma de decisiones bajo incertidumbre. Para tomar
decisiones debemos de especificar la noción de ~utilidad~ asociada a cada opción
que podemos tomar. La decisión ~óptima Bayesiana~ corresponde a la que maximiza la
utilidad esperada. Buscaremos ejemplificar cómo podemos utilizar ~Stan~ para
estimar la distribución de posibles respuestas bajo decisiones y calcular 
utilidades esperadas.

* Definición de un problema de decisión

Siguiendo a citep:Gelman2014a un problema de decisión Bayesiano necesita de los siguientes componentes:
1. Definir un conjunto de posibles resultados $X$.
2. Definir un conjunto de posibles decisiones $D$.
3. Definir una función de utilidad que contraste la decisión, $d$, contra el resultado $x$, la cual denotamos por $U(x, d)$. 
4. Especificar nuestro estado de conocimiento sobre las posibles realizaciones de posibles resultados a través de $\pi(x)$.

#+BEGIN_NOTES
También es usual, como veremos adelante, que consideremos una $\pi(x)$ para cada
decisión que podamos tomar, lo cual lo denotamos por $\pi(x|d)$ si fuera necesario. 
#+END_NOTES

#+REVEAL: split
Con lo cual podemos escoger la decisión $d^*$ que obtenga la mejor utilidad esperada
\begin{align}
d^* = \arg \max_d \bar U [d]\,,
\end{align}
donde
\begin{align}
\bar U[d] = \mathbb{E} [U(X, d)] = \int U(x, d) \pi(x) \text{d}x\,.
\end{align}

#+REVEAL: split
Los resultados deberán de representar la mayor información posible que sea
relevante para la especificación de la función de utilidad.

** Contexto bayesiano

- Las decisiones pueden ser sobre los parámetros del modelo, $\theta$,  o cantidades observables, $\tilde y$.
- Nuestro estado de conocimiento lo definimos como la distribución posterior o predictiva posterior.
- La función de utilidad depende del contexto del problema.

** Caso: enfoque predictivo

Supongamos que tenemos el siguiente problema de decisión bayesiano con un ~enfoque predictivo~:
- Los *estados* posibles son ~cantidades observables~ $\tilde y$.
- Las *decisiones* que podemos tomar son sobre /todas/ los posibles ~funciones de
  probabilidad~ relevantes para nuestro problema. Es decir, cualquier $d(\tilde
  y)$ donde $d$ es una distribución de probabilidad sobre cantidades
  observables.
- La *función de utilidad* que escogeremos será ~utilidad logarítmica~, $\log (d)$.
- Nuestro *estado de conocimiento* sobre los estados inciertos lo reflejamos a
  través de la ~distribución predictiva posterior~, $\pi(\tilde y |
  \underline{y}_n)$.

#+REVEAL: split
La decisión que maximiza la utilidad esperada bajo nuestro estado de
conocimiento será la que ~maximice~
\begin{align}
\int \log {\color{orange} d(\tilde y )} \, \pi (\tilde y | \underline{y}_n) \, \text{d}\tilde y\,.
\end{align}

#+REVEAL: split
Nota que pedimos que sea la que ~minimice~
\begin{align}
- \int \log {\color{orange} d(\tilde y )} \, \pi (\tilde y | \underline{y}_n) \, \text{d}\tilde y\,, 
\end{align}
que es justamente la ~entropía cruzada~ entre dos distribuciones y que sabemos
tiene un punto óptimo siempre y cuando utilicemos la misma distribución con la
que reflejamos nuestro estado de conocimiento.

#+REVEAL: split
Es decir, bajo un ~enfoque predictivo~ nuestra mejor decisión bajo utilidad
logarítmica es utilizar la densidad predictiva posterior.

** Caso: enfoque de inferencia

Supongamos que tenemos el siguiente problema de decisión bayesiano con un ~enfoque de inferencia~:
- Los *estados* posibles son ~la configuración del modelo~ que especifica un modelo
  probabilístico, $\theta$.
- Las *decisiones* que podemos tomar son /todas/ los posibles ~funciones de
  probabilidad~ relevantes para nuestro poblema. Es decir, cualquier $d(\theta)$
  donde $d$ es una distribución sobre configuraciones de un modelo.
- La *función de utilidad*  que escogeremos será ~utilidad logarítmica~, $\log (d)$.
- Nuestro *estado de conocimiento* sobre los estados inciertos lo reflejamos a
  través de la ~distribución posterior~, $\pi(\theta| \underline{y}_n)$.


*** Pregunta: 
:PROPERTIES:
:reveal_background: #00468b
:END:
¿Cuál será la mejor decisión que podemos tomar en este escenario? 


* Análisis de decisión

Vamos a seguir el [[https://mc-stan.org/docs/2_29/stan-users-guide/example-decision-analysis.html][ejemplo]] que está en la documentación de ~Stan~. En este
escenario el tomador de decisiones tiene que decidir el medio de transporte para
llegar a su trabajo: caminar, bicicleta, transporte público o taxi.

#+REVEAL: split
A lo largo del año ha registrado 200 días de trayectos a su trabajo y ha
registrado el tiempo que le toma llegar.

** Definición de ~decisiones~ y ~observaciones~ 

- Las *decisiones* son el medio de transporte codificadas numéricamente.
- Los *resultados*  $X= \mathbb{R}\times \mathbb{R}$ que observamos son el tiempo $t$ que toma y el costo $c$ asociado a ese tiempo, $x = (c, t)$.

** Definición de ~estado de conocimiento~

Necesitamos definir $\pi(x | d)$ la distribución de resultados posibles sujeta a
la decisión que se ha tomado. Bajo el enfoque Bayesiano ésta será la distribución
predictiva posterior de una observación condicional en la historia que hemos visto
\begin{align}
\pi(\tilde x  | d, \underline{x}_n, \underline{d}_n) = \int \pi(\tilde x | d, \theta) \,  \pi(\theta | \underline{x}_n, \underline{d}_n) \, \text{d}\theta\,.
\end{align}

#+REVEAL: split
Por simplicidad utilizamos una distribución log-normal para los tiempos de llegada bajo cada transporte. Es decir, para una observación $x_n = (c_n, t_n)$ asociada a la decisión $d_n$ consideramos
\begin{align}
t_n \sim \mathsf{LogNormal} \left( \mu_{[d_n]}, \sigma_{[d_n]} \right)\,.\\
c_n \sim \mathsf{LogNormal} \left( \nu_{[d_n]}, \tau_{[d_n]} \right)\,.
\end{align}

#+BEGIN_NOTES
Decimos que una variable aleatoria se distribuye log-normal, denotado como $Y \sim \mathsf{logNormal}(\mu, \sigma)$, si $\log Y \sim \mathsf{Normal}(\mu, \sigma)$. 
#+END_NOTES

#+REVEAL: split
Las previas que utilizamos para el tiempo de llegada en cada modo de transporte, $k \in \{1, \ldots, 4\}$, son
\begin{align}
\mu_k \sim \mathsf{Normal}(0, 5)\,, \\
\sigma_k \sim \mathsf{logNormal}(0, 1)\,.
\end{align}

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/transport-times-prior.jpeg  :exports results :results output graphics file
  set.seed(108727)
  tibble( id = 1:1000,
         mu = rnorm(1000, 0, 5),
         sigma = exp(rnorm(1000, 0, 1))) |>
    nest(data = c(mu, sigma)) |>
    mutate(y = map_dbl(data, function(params){
      exp(rnorm(1, params$mu, sd = params$sigma))
    })) |>
    unnest(data) |>
    mutate(log_time = log(y)) |>
    pivot_longer(cols = c(mu, sigma, log_time)) |>
    ggplot(aes(value)) +
    geom_histogram(bins = 20, color = "white") +
    facet_wrap(~name, scales = "free") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/transport-times-prior.jpeg]]

#+REVEAL: split
Las previas que utilizamos para los costos por cada modo de transporte, $k \in \{1, \ldots, 4\}$, son
\begin{align}
\nu_k \sim \mathsf{Normal}(0, 5)\,, \\
\tau_k \sim \mathsf{logNormal}(0, 1)\,.
\end{align}

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/transport-costs-prior.jpeg  :exports results :results output graphics file
  set.seed(108)
  tibble( id = 1:1000,
         nu = rnorm(1000, 0, 5),
         tau = exp(rnorm(1000, 0, 1))) |>
    nest(data = c(nu, tau)) |>
    mutate(y = map_dbl(data, function(params){
      exp(rnorm(1, params$nu, sd = params$tau))
    })) |>
    unnest(data) |>
    mutate(log_cost = log(y)) |>
    pivot_longer(cols = c(nu, tau, log_cost)) |>
    ggplot(aes(value)) +
    geom_histogram(bins = 20, color = "white") +
    facet_wrap(~name, scales = "free") + sin_lineas
#+end_src

#+RESULTS:
[[file:../images/transport-costs-prior.jpeg]]

#+REVEAL: split
El conjunto de parámetros del modelo que marginalizará en la predictiva posterior es
\begin{align}
\theta = (\mu_{1:4}, \sigma_{1:4}, \nu_{1:4}, \tau_{1:4})\,.
\end{align}

** Definición ~función de utilidad~

Digamos que el tomador de decisión evalúa su tiempo de traslado de manera lineal
y que el tiempo invertido en transporte lo evalúa en $25 por cada momento que
éste pasa en su trayecto, por lo que la función de utilidad es
\begin{align}
U(c, t) = - (c + 25 \cdot t)\,.
\end{align}

#+BEGIN_NOTES
Nota que podríamos considerar una utilidad distinta para cada modo de
transporte, $U(x,d)$, de tal manera que se reflejen costos individuales de cada
medio de transporte.
#+END_NOTES

** Cálculo de utilidad esperada

Lo que necesitamos ahora es poder calcular la utilidad esperada de cada una de
las posibles decisiones y tomar la que minimice dicha función. El siguiente código aprovecha que
nuestro espacio de posibles decisiones es pequeño.

#+begin_src stan :tangle ../modelos/decision/transporte.stan
  functions {
    real U(real c, real t) {
      return -(c + 25 * t);
    }
  }
  data {
    int<lower=0> N;
    array[N] int<lower=1, upper=4> d;
    array[N] real c;
    array[N] real<lower=0> t;
  }
  parameters {
    vector[4] mu;
    vector<lower=0>[4] sigma;
    array[4] real nu;
    array[4] real<lower=0> tau;
  }
  model {
    mu ~ normal(0, 1);
    sigma ~ lognormal(0, 0.25);
    nu ~ normal(0, 20);
    tau ~ lognormal(0, 0.25);
    t ~ lognormal(mu[d], sigma[d]);
    c ~ lognormal(nu[d], tau[d]); 
  }
  generated quantities {
    array[4] real util;
    for (k in 1:4) {
      util[k] = U(lognormal_rng(mu[k], sigma[k]),
                  lognormal_rng(nu[k], tau[k]));
    }
  }
#+end_src

#+REVEAL: split
Lo que esta calculando ~Stan~ son los términos para estimar la utilidad esperada
por medio de un ~estimador Monte Carlo~. Esto lo vemos de la expresión
\begin{align}
\bar U [d] &= \mathbb{E}[U(X, d) |  \underline{x}_n, \underline{d}_n] = \int U(x, d) \cdot \pi(x | d, \theta) \cdot \pi(\theta | \underline{x}_n, \underline{d}_n ) \, \text{d}\theta \, \text{d}x\,,\\
&\approx \frac{1}{M} \sum_{m = 1}^{M} U(x^{(m)}) \,,
\end{align}
donde
\begin{gather}
x^{(m)} \sim \pi(x | d, \theta^{(m)})\,,\\
\theta^{(m)} \sim \pi(\theta | \underline{x}_n, \underline{d}_n )\,.
\end{gather}

* Funciones de utilidad

La función de utilidad depende de la aplicación. En particular, de las
características del problema y de la pregunta que se requiere responder con el
análisis.

#+REVEAL: split
Bajo el contexto de ~modelado predictivo~ vimos que hace sentido utilizar la
log-densidad predictiva posterior para tomar decisiones. Esto es cuando queremos
escoger un modelo probabilístico con buenas capacidades predictivas.

#+REVEAL: split
Sin embargo, en algunas aplicaciones nos puede interesar hacer predicciones
puntuales. Por ejemplo, en una aplicación nos puede interesar utilizar el
concepto de ~pérdida cuadrática~ para tomar decisiones. La función de utilidad la podemos definir como
\begin{align}
U_{\mathsf{Q}}(\tilde y, d) = - (\tilde y - d)^2\,.
\end{align}

#+REVEAL: split
De manera análoga, podemos utilizar nuestras nociones de ~pérdida en valor
absoluto~ o ~pérdida en valor absoluto relativo~ para definir utilidades. Incluso
podemos utilizar ~pérdidas por intervalos~ o ~pérdidas por predicción
correcta/incorrecta~ (pérdida 1-0).

#+REVEAL: split
En la literatura existen algunos ejemplos de funciones de utilidad como en la
Sección 9.9.1 de citep:Martin2021 o la Sección 9.4 de citep:Gelman2014a. Los
libros citep:Gilboaa o citep:Smith2010 proveen de un muy buen marco teórico para
estos conceptos.

** Ejemplo: Prueba Bechdel

Consideremos nuestro ejemplo del curso sobre las películas que pasan la prueba
de Bechdel.  Consideremos nuestra previa como una $\mathsf{Beta}(5,
11)$. También consideremos análisis predictivo bajo el enfoque de funciones de
pérdida para las predicciones:
1. Utilidad cuadrática;
2. Utilidad 1-0.
3. Utilidad por intervalos. 

#+begin_src R  :exports none :resuls none
  library(bayesrules)
  set.seed(108727)
  data <- bechdel |>
    sample_n(20) |>
    mutate(test = ifelse(binary == "PASS", 1, 0)) |>
    select(-title, -binary)
#+end_src

#+REVEAL: split
El código que utilizaremos en ~Stan~ es el siguiente: 

#+begin_src stan :tangle ../modelos/decision/peliculas-bechdel.stan
  functions {
    real quadraticUtility(int y_tilde, int d) {
      return -(y_tilde - d)^2; 
    }
    real zeroOneUtility(int y_tilde, int d){
      if (y_tilde == d) {
        return 1;
      } else {
        return 0;
      } 
    }
    real intervalUtility(int y_tilde, int d){
      if (fabs(y_tilde - d) < 10) {
        return 0;
      } else {
        return -fabs(y_tilde - d); 
      }
    }
  }

  data {
    int<lower=0> N;
    int<lower=0> K;
    array[N] int<lower=0, upper=1> test;
  }

  parameters {
    real<lower=0, upper=1> theta; 
  }

  model {
    theta ~ beta(5, 11); 
    test ~ bernoulli(theta);
  }

  generated quantities {
    array[K] real utilQuad;
    array[K] real utilZeroOne;
    array[K] real utilInterval; 
    for (kk in 1:K) {
      utilQuad[kk] = quadraticUtility(binomial_rng(K, theta), kk);
      utilZeroOne[kk] = zeroOneUtility(binomial_rng(K, theta), kk);
      utilInterval[kk] = intervalUtility(binomial_rng(K, theta), kk); 
    }
  }
#+end_src

#+begin_src R :exports none :results none
  modelos_files <- "modelos/compilados/decision"
  ruta <- file.path("modelos/decision/peliculas-bechdel.stan")
  modelo <- cmdstan_model(ruta, dir = modelos_files)
#+end_src


#+begin_src R :exports code :results none
  posterior <- modelo$sample(data = c(N = nrow(data),
                                      K = 20,
                                      data),
                             refresh = 10000,
                             iter_sampling = 4000,
                             seed = 108727)
#+end_src

#+REVEAL: split
Los resultados se muestran a continuación de manera gráfica ([[fig:bechdel]]). 

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/bechdel-utilidad-cuadratica.jpeg :exports results :results output graphics file

  posterior$draws(c("utilQuad", "utilZeroOne", "utilInterval"), format = "df") |>
    as_tibble() |>
    pivot_longer(cols = 1:60) |>
    mutate(decision = rep(1:20, 3 * 4 * 4000),
           utility  = rep(rep(c("Cuadratica", "Uno Cero", "Intervalo"),
                              each = 20), 4 * 4000),
           utility = fct_inorder(utility)) |>
    group_by(utility, decision) |>
    summarise(expected.util = mean(value),
              ribbon.lo = quantile(value, .10),
              ribbon.hi = quantile(value, .90)) |>
    ungroup() |>
    ggplot(aes(decision - .5, expected.util)) +
    ## geom_line() + geom_point() +
    geom_step() + 
    geom_vline(xintercept = 9, color = 'red', lty = 2) +
    facet_wrap(~utility, scales = "free_y") + 
    sin_lineas +
    ylab("Utilidad Esperada") +
    xlab("Decisión") 

#+end_src
#+name: fig:bechdel
#+caption: Utilidad esperada bajo distintas funciones de utilidad.
#+RESULTS:
[[file:../images/bechdel-utilidad-cuadratica-aprox-continua.jpeg]]

#+REVEAL: split
Nota que bajo pérdida cuadrática y pérdida 1-0 podemos identificar un único
punto máximo de utilidad esperada. Bajo pérdida por intervalos, no.

#+BEGIN_NOTES
Bajo ciertas funciones de utilidad podemos identificar los resúmenes adecuados
que maximicen la función de utilidad. Por ejemplo, para pérdida cuadrática
corresponde el valor esperado posterior (en el ejemplo de las películas el de la
distribución predictiva posterior). Para pérdida 1-0, la moda.
#+END_NOTES

* Decisiones continuas

El ejemplo anterior utilizaba decisiones discretas (o un espacio de decisiones
discretas). Si las decisiones fueran sobre un continuo, el problema se vuelve mas
complicado, para lo cual las capacidades actuales de ~Stan~ son limitadas.

#+name: fig:bechdel-cont
#+caption: Utilidad esperada bajo distintas funciones de utilidad.
#+RESULTS:
[[file:../images/bechdel-utilidad-cuadratica-aprox-continua.jpeg]]


* Referencias                                                         :latex:

bibliographystyle:abbrvnat
bibliography:references.bib

