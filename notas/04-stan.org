#+TITLE: EST-46115: Modelación Bayesiana
#+AUTHOR: Prof. Alfredo Garbuno Iñigo
#+EMAIL:  agarbuno@itam.mx
#+DATE: ~Stan~
#+STARTUP: showall
:REVEAL_PROPERTIES:
#+LANGUAGE: es
#+OPTIONS: num:nil toc:nil timestamp:nil
#+REVEAL_REVEAL_JS_VERSION: 4
#+REVEAL_THEME: night
#+REVEAL_SLIDE_NUMBER: t
#+REVEAL_HEAD_PREAMBLE: <meta name="description" content="Modelación Bayesiana">
#+REVEAL_INIT_OPTIONS: width:1600, height:900, margin:.2
#+REVEAL_EXTRA_CSS: ./mods.css
#+REVEAL_PLUGINS: (notes)
:END:
:LATEX_PROPERTIES:
#+OPTIONS: toc:nil date:nil author:nil tasks:nil
#+LANGUAGE: sp
#+LATEX_CLASS: handout
#+LATEX_HEADER: \usepackage[spanish]{babel}
#+LATEX_HEADER: \usepackage[sort,numbers]{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc} 
#+LATEX_HEADER: \usepackage[capitalize]{cleveref}
#+LATEX_HEADER: \decimalpoint
#+LATEX_HEADER:\usepackage{framed}
#+LaTeX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \definecolor{backcolour}{rgb}{.95,0.95,0.92}
#+LaTeX_HEADER: \definecolor{codegray}{rgb}{0.5,0.5,0.5}
#+LaTeX_HEADER: \definecolor{codegreen}{rgb}{0,0.6,0} 
#+LaTeX_HEADER: {}
#+LaTeX_HEADER: {\lstset{language={R},basicstyle={\ttfamily\footnotesize},frame=single,breaklines=true,fancyvrb=true,literate={"}{{\texttt{"}}}1{<-}{{$\bm\leftarrow$}}1{<<-}{{$\bm\twoheadleftarrow$}}1{~}{{$\bm\sim$}}1{<=}{{$\bm\le$}}1{>=}{{$\bm\ge$}}1{!=}{{$\bm\neq$}}1{^}{{$^{\bm\wedge}$}}1{|>}{{$\rhd$}}1,otherkeywords={!=, ~, $, \&, \%/\%, \%*\%, \%\%, <-, <<-, ::, /},extendedchars=false,commentstyle={\ttfamily \itshape\color{codegreen}},stringstyle={\color{red}}}
#+LaTeX_HEADER: {}
#+LATEX_HEADER_EXTRA: \definecolor{shadecolor}{gray}{.95}
#+LATEX_HEADER_EXTRA: \newenvironment{NOTES}{\begin{lrbox}{\mybox}\begin{minipage}{0.95\textwidth}\begin{shaded}}{\end{shaded}\end{minipage}\end{lrbox}\fbox{\usebox{\mybox}}}
#+EXPORT_FILE_NAME: ../docs/04-stan.pdf
:END:
#+EXCLUDE_TAGS: toc latex
#+PROPERTY: header-args:R :session tutorial :exports both :results output org :tangle ../rscripts/04-stan.R :mkdirp yes :dir ../


#+BEGIN_NOTES
*Profesor*: Alfredo Garbuno Iñigo | Primavera, 2022 | Stan.\\
*Objetivo*. Un primer acercamiento a ~Stan~,  sintaxis, manipulación de objetos y visualizaciones sencillas. Además un caso de estudio donde empezaremos a ver ciertos errores en el ajuste de los modelos.\\
*Lectura recomendada*: Sección 6.2.1 de citep:Dogucu2021. 
#+END_NOTES

* Contenido                                                             :toc:
:PROPERTIES:
:TOC:      :include all  :ignore this :depth 3
:END:
:CONTENTS:
- [[#introducción][Introducción]]
  - [[#estructura-del-código][Estructura del código]]
  - [[#visualizaciones][Visualizaciones]]
  - [[#ejercicio-0][Ejercicio (0)]]
  - [[#ejercicio-1][Ejercicio (1)]]
  - [[#ejercicio-2][Ejercicio (2)]]
- [[#caso-escuelas][Caso: escuelas]]
- [[#primer-modelo-en-stan][Primer modelo en Stan]]
  - [[#simulación][Simulación]]
  - [[#alternativas--rstan][Alternativas:  Rstan]]
  - [[#generando-mas-simulaciones][Generando mas simulaciones]]
  - [[#haciendo-tweaks-en-el-simulador][Haciendo tweaks en el simulador]]
- [[#cambiando-ligeramente-el-modelo][Cambiando ligeramente el modelo]]
- [[#regularización-bayesiana][Regularización Bayesiana]]
  - [[#formulación-probabilística][Formulación probabilística]]
  - [[#regularización-en-regresión-diabetes][Regularización en regresión (diabetes)]]
  - [[#regularización-en-regresión-carros][Regularización en regresión (carros)]]
:END:

#+begin_src R :exports none :results none
  ## Setup --------------------------------------------
  library(cmdstanr)
  library(posterior)
  library(bayesplot)

  library(tidyverse)
  library(patchwork)
  library(scales)
  ## Cambia el default del tamaño de fuente 
  theme_set(theme_linedraw(base_size = 25))

  ## Cambia el número de decimales para mostrar
  options(digits = 2)

  sin_lineas <- theme(panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank())
  color.itam  <- c("#00362b","#004a3b", "#00503f", "#006953", "#008367", "#009c7b", "#00b68f", NA)

  sin_lineas <- theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
  sin_leyenda <- theme(legend.position = "none")
  sin_ejes <- theme(axis.ticks = element_blank(), axis.text = element_blank())

  ## Funciones auxiliares
  print_file <- function(file) {
    cat(paste(readLines(file), "\n", sep=""), sep="")
  }
#+end_src

* Introducción

Veremos ejemplos sencillos sobre la sintaxis de ~Stan~ (citep:Carpenter2017) con
el cual simularemos realizaciones de parámetros ~no observables~ para los cuales
tenemos un ~estado de conocimiento~ reflejado en la distribución posterior.


Habíamos visto que los /bayesics/ son los componentes:
1) Un conjunto de datos. 
2) Supuestos del proceso generador de  datos. 
3) Conocimiento previo sobre los componentes que rigen el modelo.


Para ~Stan~ tenemos que seguir algo muy similar. Es decir,
1) Definir el modelo.
2) Ingestar los datos.
3) Darle /play/ al botón de inferencia.


Un modelo de ~Stan~ se escribe en un archivo de texto y es una secuencia de
bloques con nombre. En general el esqueleto es como sigue: 

#+caption: Función /personalizada/ para imprimir un archivo de texto.
#+begin_src R :exports code :results none
  print_file("modelos/tutorial/esqueleto.stan")
#+end_src
\newpage
#+caption: Estructura de un modelo de ~Stan~.
#+begin_src stan :eval never
  functions {
      // ... function declarations and definitions ...
  }
  data {
      // ... declarations ...
  }
  transformed data {
      // ... declarations ... statements ...
  }
  parameters {
      // ... declarations ...
  }
  transformed parameters {
      // ... declarations ... statements ...
  }
  model {
      // ... declarations ... statements ...
  }
  generated quantities {
      // ... declarations ... statements ...
  }
#+end_src

En general ~todos~ los bloques ~son opcionales~, y *no es necesario* tener todos para
compilar un modelo. Para mas información puedes consultar [[https://mc-stan.org/docs/2_26/reference-manual/overview-of-stans-program-blocks.html][la guía de Stan]].

** Estructura del código

- Un bloque ~data~. Por ejemplo, $Y$ el número observado de éxitos en 10 pruebas. 
- Un bloque ~parameters~. Por ejemplo, $\theta$  la tasa de éxito en la realización de las pruebas. 
- Un bloque ~model~. Por ejemplo, $Y\sim \mathsf{Binomial}(10, \theta)$  y $\theta \sim \mathsf{Beta}(2,2)$.


El código es:
#+begin_src stan :exports code :eval none
  data {
    int<lower = 0, upper = 10> Y;
  }
  parameters {
    real<lower = 0, upper = 1> theta;
  }
  model {
    Y ~ binomial(10, theta);
    theta ~ beta(2, 2);
  }
#+end_src

#+caption: Código necesario para interactuar con ~Stan~ desde ~R~.
#+begin_src R :exports code :results none
  ## Modelo Beta-Binomial --------------------------------
  modelos_files <- "modelos/compilados/tutorial"
  ruta <- file.path("modelos/tutorial/beta-binomial.stan")
  modelo <- cmdstan_model(ruta, dir = modelos_files)
#+end_src

#+BEGIN_NOTES
     Para leer mas sobre la herramienta y sus interacción desde línea de comandos puedes consultar la [[https://mc-stan.org/docs/2_24/cmdstan-guide-2_24.pdf][documentación de ~Stan~]].
#+END_NOTES


#+begin_src R :exports both :results org
  class(modelo)
#+end_src
#+caption: Tipo de objeto que regresa la compilación del modelo. 
#+RESULTS:
#+begin_src org
[1] "CmdStanModel" "R6"
#+end_src


Con esto tenemos un ~objeto~ (OOP) con distintos ~métodos~ que podemos
utilizar. Puedes consultar [[https://mc-stan.org/cmdstanr/reference/CmdStanModel.html][aquí]] los métodos disponibles de dichos objetos.

#+DOWNLOADED: screenshot @ 2022-02-23 20:32:57
#+caption: Métodos de objetos de la clase ~CmdStanModel~. 
#+attr_html: :width 1200 :align center
[[file:images/20220223-203257_screenshot.png]]


Por ejemplo, tenemos un método que puede generar muestras del ~modelo probabilístico~ que se
definió en el bloque de modelo.


Necesitamos los datos en un formato muy especial (una lista):
#+begin_src R :exports code :results none
  data.list <- list(Y = 7) 
#+end_src

#+BEGIN_NOTES
La interacción desde ~R~ con ~Stan~ necesita los datos ordenados en =listas con nombres=. En ~Python~ éstos son =diccionarios=. Ambos, generalizan a archivos en formato ~JSON~. 
#+END_NOTES

Para darle /play/ :
#+begin_src R :exports both :results org
  muestras <- modelo$sample(data = data.list, 
                            chains = 1, 
                            iter=1500, 
                            iter_warmup=500, 
                            seed=483892929, 
                            refresh=500)
#+end_src
#+caption: Resultados de muestreo. 
#+RESULTS:
#+begin_src org
Running MCMC with 1 chain...

Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) 
Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) 
Chain 1 Iteration:  501 / 2000 [ 25%]  (Sampling) 
Chain 1 Iteration: 1000 / 2000 [ 50%]  (Sampling) 
Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) 
Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) 
Chain 1 finished in 0.0 seconds.
#+end_src


El resultado es:
#+begin_src R :exports both :results org
  class(muestras)
#+end_src
#+caption: Tipo de objeto que regresa la compilación del modelo. 
#+RESULTS:
#+begin_src org
[1] "CmdStanMCMC" "CmdStanFit"  "R6"
#+end_src

Donde se pueden explorar los métodos de estos objetos en [[https://mc-stan.org/cmdstanr/reference/CmdStanMCMC.html][la documentación]]. 

** Visualizaciones

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/beta-binomial-traces.jpeg :exports results :results output graphics file
  mcmc_trace(muestras$draws(), pars = "theta") +
    sin_lineas +
  geom_hline(yintercept = 9/14, lty = 2, color = 'black')
#+end_src
#+caption: Trazas (trayectorias) del componente $\theta$ en el modelo Beta-Binomial. 
#+RESULTS:
[[file:../images/beta-binomial-traces.jpeg]]

#+BEGIN_NOTES
Nota: tuvimos que definir qué parámetros queremos en la visualización. Por
/default/ incluye un misterioso ~lp__~ que hace referencia a la evaluación de la
log-posterior para cada elemento de la simulación. Adicional, nota (en el código
fuente) que la sintaxis para el gráfico utiliza la gramática y las funciones de
~ggplot2~.
#+END_NOTES


#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/beta-binomial-histogramas.jpeg :exports results :results output graphics file
  # Histogram of the Markov chain values
  g1 <- mcmc_hist(muestras$draws(), pars = "theta") + 
    yaxis_text(TRUE) + 
    ylab("count") + sin_lineas

  # Density plot of the Markov chain values
  g2 <- mcmc_dens(muestras$draws(), pars = "theta") + 
    yaxis_text(TRUE) + 
    ylab("density") + sin_lineas

  g1 + g2
#+end_src
#+caption: Histogramas del componente $\theta$ en el modelo Beta-Binomial. 
#+RESULTS:
[[file:../images/beta-binomial-histogramas.jpeg]]

** Ejercicio (0)
:PROPERTIES:
:reveal_background: #00468b
:END:
¿Cómo utilizarías ~Stan~ para generar números aleatorios de:
1) la distribución previa;
2) la distribución predictiva posterior?

Utiliza el ejemplo Beta-Binomial de arriba para ponerlo en práctica.
/Hint/: revisa la documentación del bloque ~generated quantities~. 

** Ejercicio (1)
:PROPERTIES:
:reveal_background: #00468b
:END:

Repite lo anterior para un modelo Poisson-Gamma. Es decir, para una colección de
observaciones $(Y_1, Y_2) = (2, 9)$ donde suponemos que $Y_j
\overset{\mathsf{iid}}{\sim} \mathsf{Poisson}(\lambda)$ y $\lambda \sim
\mathsf{Exponencial}(3)$.

/Hints:/ Revisa la documentación para definir vectores (en este caso de longitud 2) en el bloque de datos. 

** Ejercicio (2)
:PROPERTIES:
:reveal_background: #00468b
:END:
Utiliza el ambiente de ~Stan~ para encontrar el estimador de Máxima verosimillitud de los dos problemas que hemos trabajado. Es decir, el caso Beta-Binomial y Poisson-Gamma. 

* Caso: escuelas

Utilizaremos los datos de un estudio de desempeño de 8 escuelas
(citep:Rubin1981,Gelman2014a). Los datos consisten en el puntaje promedio de
cada escuela ~y~ y los errores estándar reportados ~sigma~ la dispersión de los
resultados de dicha prueba.


#+begin_src R :exports code :results none
  ## Caso: escuelas --------------------------------------
  data <- tibble( id = factor(seq(1, 8)), 
                  y = c(28, 8, -3, 7, -1, 1, 18, 12), 
                  sigma = c(15, 10, 16, 11, 9, 11, 10, 18))
#+end_src

En este caso se utiliza un modelo normal para los resultados de cada escuela
\begin{align}
y_j \sim \mathsf{N}(\theta_j, \sigma_j), \qquad j = 1, \ldots, J\,,
\end{align}

donde $J = 8$, y $\theta_j$ representa el promedio de los alumnos de escuela que
no observamos pero del cual tenemos un estimador $y_j$.


Nota que tenemos $J$ valores distintos para $\theta_j$ y $\sigma_j$. Dado que 
esperamos que las escuelas provengan de la misma población de escuelas asumimos
que
$$ \theta_j \sim \mathsf{N}(\mu, \tau), \qquad j = 1, \ldots, J\,,$$

donde $\mu$ representa la media poblacional (el promedio en el sistema escolar)
y $\tau$ la desviación estándar alrededor de este valor.


Representamos nuestra incertidumbre en estos dos valores por medio de

$$ \mu \sim \mathsf{N}(0, 5), \qquad \tau \sim \textsf{Half-Cauchy}(0,5)\,, $$

lo cual representa información poco precisa de estos valores poblacionales. 

* Primer modelo en ~Stan~

La forma en que escribimos el modelo en ~Stan~ es de manera generativa (/bottom up/):
\begin{subequations}
\begin{gather}
\mu \sim \mathsf{N}(0, 5) \,,\\ 
\tau \sim \textsf{Half-Cauchy}(0,5) \,,\\
\theta_j \sim \mathsf{N}(\mu, \tau), \qquad j = 1, \ldots, J \,,\\
y_j \sim \mathsf{N}(\theta_j, \sigma_j), \qquad j = 1, \ldots, J\,.
\end{gather}
\end{subequations}


#+begin_src R :exports code :results org
  print_file("modelos/caso-escuelas/modelo-escuelas.stan")
#+end_src
#+caption: Código del modelo para el desempeño de las escuelas. 
#+begin_src stan :eval never
  data {
    int<lower=0> J;
    real y[J];
    real<lower=0> sigma[J];
  }
  parameters {
    real mu;
    real<lower=0> tau;
    real theta[J];
  }
  model {
    mu ~ normal(0, 5);
    tau ~ cauchy(0, 5);
    theta ~ normal(mu, tau);
    y ~ normal(theta, sigma);
  }
#+end_src


Nota que ~sigma~ está definida como /parte del conjunto de datos/ que el usuario
debe de proveer. Aunque es un parámetro en nuestro modelo (verosimilitud) no está
sujeto al proceso de inferencia. Por otro lado, nota que la declaración no se
hace de manera componente por componente, sino de forma ~vectorizada~. 


Una vez escrito nuestro modelo, lo podemos compilar utilizando la librería de
~cmdstanr~, que es la interface con ~Stan~ desde ~R~.

#+begin_src R :exports code :results none
  modelos_files <- "modelos/compilados/caso-escuelas"
  ruta <- file.path("modelos/caso-escuelas/modelo-escuelas.stan")
  modelo <- cmdstan_model(ruta, dir = modelos_files)
#+end_src

Los datos que necesita el bloque ~data~ se pasan como una /lista con nombres/.

#+begin_src R :exports code :results none
  data_list <- c(data, J = 8)
#+end_src

** Simulación 

Contra todas las recomendaciones usuales, corramos sólo una cadena corta:

#+begin_src R :exports both :results org
  muestras <- modelo$sample(data = data_list, 
                            chains = 1, 
                            iter=700, 
                            iter_warmup=500, 
                            seed=483892929, 
                            refresh=1200)
#+end_src
#+caption: Resultados del muestreador en el modelo. 
#+RESULTS:
#+begin_src org
Running MCMC with 1 chain...

Chain 1 Iteration:    1 / 1200 [  0%]  (Warmup) 
Chain 1 Iteration:  501 / 1200 [ 41%]  (Sampling) 
Chain 1 Iteration: 1200 / 1200 [100%]  (Sampling) 
Chain 1 finished in 0.1 seconds.

Warning: 53 of 700 (8.0%) transitions ended with a divergence.
This may indicate insufficient exploration of the posterior distribution.
Possible remedies include: 
  ,* Increasing adapt_delta closer to 1 (default is 0.8) 
  ,* Reparameterizing the model (e.g. using a non-centered parameterization)
  ,* Using informative or weakly informative prior distributions
#+end_src


El muestreador en automático nos regresa ciertas alertas las cuales podemos
inspeccionar más a fondo con el siguiente comando:

#+begin_src R :exports both :results org
  muestras$cmdstan_diagnose()
#+end_src
#+caption: Diagnósticos y resumen. 
#+RESULTS:
#+begin_src org
Processing csv files: /var/folders/lk/4hdvzkhx269df8zc5xmkqgwr0000gn/T/RtmpCUyqJo/modelo-escuelas-202202231948-1-817561.csv

Checking sampler transitions treedepth.
Treedepth satisfactory for all transitions.

Checking sampler transitions for divergences.
53 of 700 (7.6%) transitions ended with a divergence.
These divergent transitions indicate that HMC is not fully able to explore the posterior distribution.
Try increasing adapt delta closer to 1.
If this doesn't remove all divergences, try to reparameterize the model.

Checking E-BFMI - sampler transitions HMC potential energy.
The E-BFMI, 0.16, is below the nominal threshold of 0.3 which suggests that HMC may have trouble exploring the target distribution.
If possible, try to reparameterize the model.

Effective sample size satisfactory.

The following parameters had split R-hat greater than 1.1:
  tau, theta[1], theta[7]
Such high values indicate incomplete mixing and biased estimation.
You should consider regularizating your model with additional prior information or a more effective parameterization.

Processing complete.
#+end_src


Notamos que parece ser que tenemos varias transiciones divergentes, algunos
parámetros tienen una $\hat R$ tienen un valor que excede la referencia de 1.1 (lo veremos más adelante),
y parece ser que los estadisticos de energía también presentan problemas.


Podemos inspeccionar el resultado de las simulaciones utilizando:
#+begin_src R :exports both :results org
  muestras$cmdstan_summary()
#+end_src
#+caption: Resumen utilizando los métodos de ~CmdStanModel~. 
#+RESULTS:
#+begin_src org
Inference for Stan model: modelo_escuelas_model
1 chains: each with iter=(700); warmup=(0); thin=(1); 700 iterations saved.

Warmup took 0.028 seconds
Sampling took 0.042 seconds

                 Mean     MCSE   StdDev       5%    50%    95%    N_Eff  N_Eff/s    R_hat

lp__              -12      2.0      8.0      -25    -12   0.36       16      391      1.1
accept_stat__    0.76  1.1e-01  3.7e-01  4.6e-16   0.98   1.00  1.1e+01  2.5e+02  1.1e+00
stepsize__      0.086      nan  2.8e-17  8.6e-02  0.086  0.086      nan      nan      nan
treedepth__       3.9  4.1e-01  1.5e+00  1.0e+00    4.0    6.0  1.3e+01  3.1e+02  1.1e+00
n_leapfrog__       28  4.2e+00  2.3e+01  3.0e+00     19     63  3.0e+01  7.1e+02  1.1e+00
divergent__     0.076  6.0e-02  2.6e-01  0.0e+00   0.00    1.0  1.9e+01  4.6e+02  1.1e+00
energy__           17  2.0e+00  8.5e+00  4.0e+00     17     30  1.7e+01  4.2e+02  1.1e+00

mu                4.0     0.47      3.5     -1.7    3.4    9.7       55     1313      1.0
tau               2.9     0.55      3.0     0.32    1.7    8.9       30      704      1.1
theta[1]          5.4     0.60      5.1     -1.6    4.0     15       74     1759      1.1
theta[2]          4.4     0.56      4.8     -2.6    3.4     12       72     1713      1.0
theta[3]          3.4     0.47      5.4     -5.1    3.3     11      130     3100      1.0
theta[4]          4.1     0.54      4.9     -3.6    3.4     12       82     1960      1.0
theta[5]          3.5     0.46      4.4     -4.1    3.2     11       92     2194      1.0
theta[6]          3.7     0.49      4.8     -4.7    3.6     11       99     2351     1.00
theta[7]          5.4     0.59      4.9     -1.2    4.2     14       68     1624      1.1
theta[8]          4.5     0.53      4.9     -3.0    3.6     12       85     2023      1.0

Samples were drawn using hmc with nuts.
For each parameter, N_Eff is a crude measure of effective sample size,
and R_hat is the potential scale reduction factor on split chains (at 
convergence, R_hat=1).
#+end_src


Donde además de los resúmenes usuales para nuestros parámetros de interés
encontramos resúmenes internos del simulador (los veremos mas adelante). 

** Alternativas:  ~Rstan~

Podemos utilizar las funciones de ~RStan~ (otra interfase con ~Stan~ desde ~R~)
para visualizar los resúmenes de manera alternativa.

#+begin_src R :exports both :results org
  stanfit <- rstan::read_stan_csv(muestras$output_files())
  stanfit
#+end_src
#+caption: Resumen obtenido con librería de ~Rstan~. 
#+RESULTS:
#+begin_src org
Inference for Stan model: modelo-escuelas-202202231948-1-817561.
1 chains, each with iter=1200; warmup=500; thin=1; 
post-warmup draws per chain=700, total post-warmup draws=700.

          mean se_mean  sd   2.5%    25%   50%  75% 97.5% n_eff Rhat
mu         4.0    0.47 3.5  -2.42   1.66   3.4  6.6  11.1    55  1.0
tau        2.9    0.55 3.0   0.32   0.59   1.6  4.3  11.1    29  1.1
theta[1]   5.4    0.60 5.1  -3.50   2.50   4.0  8.4  17.2    73  1.1
theta[2]   4.4    0.57 4.8  -3.99   1.62   3.4  7.5  14.3    71  1.0
theta[3]   3.4    0.48 5.4  -8.36   0.83   3.3  6.7  14.5   129  1.0
theta[4]   4.1    0.54 4.9  -5.79   1.39   3.4  7.3  13.6    82  1.0
theta[5]   3.5    0.46 4.4  -6.08   1.16   3.2  6.6  11.8    91  1.0
theta[6]   3.7    0.49 4.8  -6.97   1.04   3.6  7.0  12.7    98  1.0
theta[7]   5.4    0.59 4.9  -2.64   2.65   4.1  8.1  16.7    67  1.1
theta[8]   4.5    0.53 4.9  -4.63   1.84   3.6  7.6  14.5    84  1.0
lp__     -11.6    2.01 8.0 -25.98 -18.30 -11.9 -3.8   1.4    16  1.1

Samples were drawn using NUTS(diag_e) at Wed Feb 23 19:48:39 2022.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
#+end_src


En caso de necesitarlo podemos extraer las muestras en una tabla para poder 
procesarlas y generar visualizaciones. Por ejemplo, un gráfico de traza 
con $\tau$ que es el parámetro donde más problemas parecemos tener.

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/muestras-escuelas.jpeg :exports results :results output graphics file
  muestras_dt <- tibble(posterior::as_draws_df(muestras$draws(c("tau", "theta"))))

  g_tau <- muestras_dt |> 
     ggplot(aes(x = .iteration, y = log(tau))) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(-4, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)

  g_theta <- muestras_dt |> 
     ggplot(aes(x = .iteration, y =`theta[1]`)) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      geom_hline(yintercept = 0.7657852, lty = 2)
  g_tau /g_theta
#+end_src
#+caption: Trayectorías de las muestras del modelo para los componentes $\log \tau$ y $\theta_1$. 
#+RESULTS:
[[file:../images/muestras-escuelas.jpeg]]


Claramente no podemos afirmar que el muestreador está explorando bien la
posterior. Hay correlaciones muy altas. Si usáramos la media acumulada no
seríamos capaces de diagnosticar estos problemas.

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-media-acumulada.jpeg :exports results :results output graphics file
  muestras_dt |> 
     mutate(media = cummean(log(tau))) |> 
     ggplot(aes(x = .iteration, y = media)) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(-4, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)
#+end_src
#+caption: Media acumulada de $\log \tau$.
#+RESULTS:
[[file:../images/escuelas-media-acumulada.jpeg]]


Utilizar gráficos de dispersión bivariados nos ayuda a identificar mejor el
problema. En color salmón apuntamos las muestras con transiciones /divergentes/
(mas adelante lo explicaremos).

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-dispersion.jpeg :exports results :results output graphics file
  g1_dispersion <- muestras_dt |> 
    mutate(log_tau = log(tau)) |> 
    mcmc_scatter(
    pars = c("theta[1]", "log_tau"),
    np = nuts_params(stanfit),
    np_style = scatter_style_np(div_color = "salmon", div_alpha = 0.8)
  ) + sin_lineas+ ylim(-4, 3)
  g1_dispersion
#+end_src
#+caption: Gráfico de dispersión. Muestras en color salmón representan simulaciones /problemáticas/.
#+RESULTS:
[[file:../images/escuelas-dispersion.jpeg]]


Otra visualización muy conocida es la de coordenadas paralelas. En este tipo de
gráficos podemos observar de manera simultánea ciertos patrones en todos los
componentes.

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-coordenadas-paralelas.jpeg :exports results :results output graphics file
  posterior_cp <- as.array(stanfit)
  mcmc_parcoord(posterior_cp, 
                transform = list(tau = "log"),
                np = nuts_params(stanfit), 
                np_style = scatter_style_np(div_color = "salmon", 
                                            div_alpha = 0.5, 
                                            div_size = .5)) + 
    sin_lineas
#+end_src
#+caption: Gráfico de coordenadas paralelas. Permiten /conectar/ los distintos componentes de un vector. Color salmón representa simulaciones /problemáticas/.
#+RESULTS:
[[file:../images/escuelas-coordenadas-paralelas.jpeg]]


Y por último, también podemos explorar la autocorrelación de la cadena. 

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-autocorrelacion.jpeg :exports results :results output graphics file
  acf_theta <- mcmc_acf(posterior_cp, pars = "theta[1]", lags = 10) + sin_lineas
  acf_tau   <- mcmc_acf(posterior_cp, pars = "tau", lags = 10) + sin_lineas

  acf_tau / acf_theta
#+end_src
#+caption: Autocorrelaciones en las simulaciones. 
#+RESULTS:
[[file:../images/escuelas-autocorrelacion.jpeg]]

** Generando mas simulaciones

Hasta ahora los resultados parecen no ser buenos. Tenemos muestras con
transiciones /divergentes/ y una /correlación muy alta/ entre las muestras. Podríamos 
aumentar el número de simulaciones con la esperanza que esto permita una mejor
exploracion de la posterior:

#+begin_src R :exports code :results org
  muestras <- modelo$sample(data        = data_list, 
                            chains      = 1, 
                            iter        = 5000, 
                            iter_warmup = 5000, 
                            seed        = 483892929, 
                            refresh     = 10000)
#+end_src


#+begin_src R :exports both :results org
  stanfit <- rstan::read_stan_csv(muestras$output_files())
  stanfit
#+end_src

#+RESULTS:
#+begin_src org
Inference for Stan model: modelo-escuelas-202202222008-1-6a1634.
1 chains, each with iter=10000; warmup=5000; thin=1; 
post-warmup draws per chain=5000, total post-warmup draws=5000.

          mean se_mean  sd  2.5%    25%   50%   75% 97.5% n_eff Rhat
mu         4.0    0.16 3.3  -2.4   1.71   3.9   6.1  10.7   438    1
tau        4.2    0.22 3.3   0.6   1.91   3.4   5.5  12.7   224    1
theta[1]   6.2    0.23 5.9  -3.5   2.25   5.4   9.0  21.0   637    1
theta[2]   4.7    0.19 5.0  -5.2   1.37   4.3   7.7  15.5   736    1
theta[3]   3.5    0.15 5.4  -8.4   0.78   3.3   6.7  13.9  1265    1
theta[4]   4.5    0.15 5.0  -5.3   1.54   4.3   7.4  14.9  1063    1
theta[5]   3.1    0.15 4.8  -7.3   0.41   3.2   6.1  12.2   962    1
theta[6]   3.6    0.15 5.0  -6.8   0.96   3.4   6.6  13.7  1154    1
theta[7]   6.2    0.30 5.4  -2.3   2.47   5.8   9.3  18.5   327    1
theta[8]   4.5    0.17 5.5  -5.9   1.42   4.3   7.7  16.5  1052    1
lp__     -16.1    0.62 5.7 -27.1 -20.25 -16.2 -12.0  -5.3    85    1

Samples were drawn using NUTS(diag_e) at Tue Feb 22 20:08:04 2022.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
#+end_src


#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-traceplot-cadenalarga.jpeg :exports results :results output graphics file
  muestras_dt <- tibble(posterior::as_draws_df(muestras$draws(c("tau", "theta[1]"))))
  muestras_dt |> 
     ggplot(aes(x = .iteration, y = log(tau))) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(-4, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)
#+end_src
#+caption: Trayectorías de simulaciones. 
#+RESULTS:
[[file:../images/escuelas-traceplot-cadenalarga.jpeg]]


Como vemos, seguimos teniendo problemas con la exploración del espacio
parametral (donde está definida nuestra distribución de $\theta$) y tenemos
dificultades en explorar esa zona con $\tau$ pequeña. Esto lo confirmamos en la
siguiente gráfica.


#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-embudo.jpeg :exports results :results output graphics file
  g2_dispersion <- muestras_dt |> 
    mutate(log_tau = log(tau)) |> 
    mcmc_scatter(
    pars = c("theta[1]", "log_tau"),
    np = nuts_params(stanfit),
    np_style = scatter_style_np(div_color = "salmon", div_alpha = 0.8)) + 
    sin_lineas+ ylim(-4, 3) +
    ggtitle("Original")

  g2_dispersion
#+end_src
#+caption: Gráficos de dispersión.
#+RESULTS:
[[file:../images/escuelas-embudo.jpeg]]


#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-promediomovil.jpeg :exports results :results output graphics file
  muestras_dt |> 
     mutate(media = cummean(log(tau))) |> 
     ggplot(aes(x = .iteration, y = media)) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(0, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)
#+end_src
#+caption: Media acumulada de $\log \tau$. 
#+RESULTS:
[[file:../images/escuelas-promediomovil.jpeg]]

#+begin_src R :exports none :results none
  muestras_cp <- muestras
  stanfit_cp <- stanfit
#+end_src

** Haciendo /tweaks/ en el simulador

Podríamos correr una cadena con algunas opciones que permitan la exploracion mas
segura de la distribución.

#+begin_src R :exports code :results none
  muestras <- modelo$sample(data        = data_list, 
                            chains      = 1, 
                            iter        = 5000, 
                            iter_warmup = 5000, 
                            seed        = 483892929, 
                            refresh     = 10000, 
                            adapt_delta = .90)
#+end_src


#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-diagnosticos-noparam.jpeg  :exports results :results output graphics file
  muestras_dt <- tibble(posterior::as_draws_df(muestras$draws(c("tau", "theta[1]"))))
  stanfit <- rstan::read_stan_csv(muestras$output_files())

  g1 <- muestras_dt |> 
     ggplot(aes(x = .iteration, y = log(tau))) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(-4, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)


  g2_dispersion_90 <- muestras_dt |> 
    mutate(log_tau = log(tau)) |> 
    mcmc_scatter(
    pars = c("theta[1]", "log_tau"),
    np = nuts_params(stanfit),
    np_style = scatter_style_np(div_color = "salmon", div_alpha = 0.8)) + 
    sin_lineas + ylim(-4, 3) +
    ggtitle("Configuración hmc")

  g1 / (g2_dispersion + g2_dispersion_90)
#+end_src
#+caption: Gráficos de comparación. 
#+RESULTS:
[[file:../images/escuelas-diagnosticos-noparam.jpeg]]

* Cambiando /ligeramente/ el modelo

Tener cuidado en la simulación del sistema Hamiltoniano nos ayuda hasta cierto
punto. Seguimos teniendo problemas y no hay garantías que nuestra simulación 
y nuestros estimadores Monte Carlo no estén sesgados.


Esta situación es muy común en /modelos jerárquicos/. El cual hemos definido como
\begin{subequations}
\begin{gather}
\mu \sim \mathsf{N}(0, 5) \,,\\ 
\tau \sim \textsf{Half-Cauchy}(0,5) \,,\\
\theta_j \sim \mathsf{N}(\mu, \tau),  \qquad j = 1, \ldots, J \,,\\
y_j \sim \mathsf{N}(\theta_j, \sigma_j),  \qquad j = 1, \ldots, J\,.
\end{gather}
\end{subequations}

El problema es la geometría de la distribución posterior. La ventaja es que
existe una solución sencilla para hacer el problema de muestreo mas
sencillo. Esto es al escribir el modelo en términos de una variable auxiliar:
\begin{subequations}
\begin{gather}
\mu \sim \mathsf{N}(0, 5) \,,\\ 
\tau \sim \textsf{Half-Cauchy}(0,5) \,,\\
\tilde{\theta}_j  \sim \mathsf{N}(0, 1), \qquad \quad j = 1, \ldots, J \,,\\
\theta_j = \mu + \tau \cdot \tilde{\theta}_j, \qquad j = 1, \ldots, J \,,\\
y_j \sim \mathsf{N}(\theta_j, \sigma_j), \qquad j = 1, \ldots, J\,.
\end{gather}
\end{subequations}

El modelo en ~Stan~ es muy parecido. La nomenclatura que se utiliza es: *modelo
centrado* para el primero, y para la reparametrización presentada en la
ecuación de arriba nos referimos a un *modelo no centrado*. 

#+begin_src R :exports code :results none
  ## Cambiando de modelo -------------------------------------
  print_file("modelos/caso-escuelas/modelo-escuelas-ncp.stan")
#+end_src

#+BEGIN_NOTES
Nota que la definición de nuevos parametros se hace desde el bloque ~transformed
parameters~ en donde la asignación se ejecuta componente por componente mientras
que la definición del modelo de probabilidad conjunto se puede hacer de manera
vectorizada.
#+END_NOTES


Igual que antes lo necesitamos compilar para hacerlo un objeto ejecutable desde
~R~.

#+begin_src R :exports code :results none
  ruta_ncp <- file.path("modelos/caso-escuelas/modelo-escuelas-ncp.stan")
  modelo_ncp <- cmdstan_model(ruta_ncp, dir = modelos_files)
#+end_src


Muestreamos de la posterior 

#+begin_src R :exports both :results org
  muestras_ncp <- modelo_ncp$sample(data = data_list, 
                            chains = 1, 
                            iter=5000, 
                            iter_warmup=5000, 
                            seed=483892929, 
                            refresh=10000)
#+end_src

#+RESULTS:
#+begin_src org
Running MCMC with 1 chain...

Chain 1 Iteration:    1 / 10000 [  0%]  (Warmup) 
Chain 1 Iteration: 5001 / 10000 [ 50%]  (Sampling) 
Chain 1 Iteration: 10000 / 10000 [100%]  (Sampling) 
Chain 1 finished in 0.3 seconds.
#+end_src


#+begin_src R :exports both :results org
  stanfit_ncp <- rstan::read_stan_csv(muestras_ncp$output_files())
  stanfit_ncp
#+end_src

#+RESULTS:
#+begin_src org
Inference for Stan model: modelo-escuelas-ncp-202202222211-1-2231c7.
1 chains, each with iter=10000; warmup=5000; thin=1; 
post-warmup draws per chain=5000, total post-warmup draws=5000.

                mean se_mean   sd   2.5%   25%   50%   75% 97.5% n_eff Rhat
mu              4.33    0.05 3.38  -2.32  2.11  4.30  6.54  10.9  4653    1
tau             3.60    0.05 3.20   0.15  1.27  2.78  4.94  12.0  4006    1
theta_tilde[1]  0.31    0.01 0.99  -1.65 -0.38  0.32  1.00   2.2  5272    1
theta_tilde[2]  0.10    0.01 0.95  -1.82 -0.52  0.11  0.73   2.0  5086    1
theta_tilde[3] -0.08    0.01 0.97  -1.99 -0.73 -0.10  0.58   1.8  4702    1
theta_tilde[4]  0.07    0.01 0.93  -1.77 -0.57  0.06  0.71   1.9  5974    1
theta_tilde[5] -0.16    0.01 0.93  -1.97 -0.79 -0.17  0.48   1.7  5767    1
theta_tilde[6] -0.08    0.01 0.94  -1.88 -0.73 -0.08  0.54   1.8  5841    1
theta_tilde[7]  0.37    0.01 0.97  -1.60 -0.27  0.39  1.03   2.2  4837    1
theta_tilde[8]  0.09    0.01 0.99  -1.81 -0.59  0.10  0.78   2.0  5059    1
theta[1]        6.10    0.08 5.60  -3.23  2.51  5.52  8.98  19.2  4663    1
theta[2]        4.89    0.07 4.68  -4.04  1.89  4.69  7.62  14.8  4869    1
theta[3]        3.88    0.08 5.35  -7.77  1.04  4.01  7.07  13.9  4454    1
theta[4]        4.74    0.06 4.81  -4.63  1.68  4.63  7.63  14.8  5533    1
theta[5]        3.55    0.07 4.80  -6.99  0.80  3.71  6.57  12.4  4890    1
theta[6]        3.88    0.07 4.97  -6.89  1.06  4.04  6.96  13.3  5390    1
theta[7]        6.29    0.07 5.16  -2.45  2.93  5.79  9.01  18.6  4983    1
theta[8]        4.87    0.08 5.35  -5.83  1.79  4.70  7.91  15.7  4705    1
lp__           -6.99    0.05 2.30 -12.16 -8.36 -6.70 -5.33  -3.4  2153    1

Samples were drawn using NUTS(diag_e) at Tue Feb 22 22:11:30 2022.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
#+end_src


Si graficamos la dispersión de $\tau$ ($\log \tau$), vemos un mejor
comportamiento (del cual ya teníamos indicios por los diagnósticos del modelo).

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-traceplot-ncp.jpeg :exports results :results output graphics file
  muestras_dt <- tibble(posterior::as_draws_df(muestras_ncp$draws(c("tau", "theta[1]", "theta_tilde[1]"))))

  muestras_dt |> 
     ggplot(aes(x = .iteration, y = log(tau))) + 
      geom_point() + sin_lineas + 
      xlab("Iteraciones") + 
      ylim(-4, 4) + 
      geom_hline(yintercept = 0.7657852, lty = 2)
#+end_src

#+RESULTS:
[[file:../images/escuelas-traceplot-ncp.jpeg]]


Si regresamos a los gráficos de dispersión para verificar que se hayan resuelto los
problemas observamos lo siguiente: 

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-dispersion-ncp.jpeg :exports results :results output graphics file
  g3 <- muestras_dt |> 
    mutate(log_tau = log(tau)) |> 
    mcmc_scatter(
    pars = c("theta_tilde[1]", "log_tau"),
    np = nuts_params(stanfit_ncp),
    np_style = scatter_style_np(div_color = "salmon", div_alpha = 0.8)) + 
    sin_lineas + ylim(-4, 3) +
    ggtitle("Variable auxiliar")

  g3_dispersion <- muestras_dt |> 
    mutate(log_tau = log(tau)) |> 
    mcmc_scatter(
    pars = c("theta[1]", "log_tau"),
    np = nuts_params(stanfit_ncp),
    np_style = scatter_style_np(div_color = "salmon", div_alpha = 0.8)) + 
    sin_lineas + ylim(-4, 3) +
    ggtitle("Re-parametrización")

  g3 + g3_dispersion
#+end_src

#+RESULTS:
[[file:../images/escuelas-dispersion-ncp.jpeg]]


#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/escuelas-dispersion-comparacion.jpeg :exports results :results output graphics file
g2_dispersion + g2_dispersion_90 + g3_dispersion
#+end_src

#+RESULTS:
[[file:../images/escuelas-dispersion-comparacion.jpeg]]

#+BEGIN_NOTES
Como lo hemos mencionado antes. Este caso ilustra uno de los casos de uso mas
conocidos de la inferencia Bayesiana, ~modelos jerárquicos~. Estos modelos surgen
en diversas aplicaciones, como regresión, análisis de series de tiempo, datos
estratificados, etc.
#+END_NOTES

* Regularización Bayesiana

Otro caso de uso bastante común y con el cual /podrían/ estar altamente familiarizados es con el concepto de ~regularización~. Por ejemplo, en modelos predictivos donde buscamos una regla de asociación $y = f_\theta(x)$. En dichos modelos $\theta$ son los parámetros que no conocemos y que ajustamos minimizando una función de pérdida /adecuada/
\begin{align}
\hat \theta = \underset{\theta}{\arg \min} \, \mathcal{J}(y, f_\theta(x))\,.
\end{align}
El problema de optimización está usualmente ~mal formulado~ en el sentido de que pequeñas perturbaciones en el conjunto de datos utilizado para /entrenar/ lleva a soluciones radicalmente distintas. En este contexto se busca ~regularizar~ el problema utilizando una función que permita restringir la solución y de esta manera tener soluciones ~estables~. Esto lo formulamos como 
\begin{align}
\hat \theta_R = \underset{\theta}{\arg \min} \,\left( \mathcal{J}(y, f_\theta(x)) + R(\theta) \right)\,.
\end{align}
Esto es bastante usual en la solución de problemas inversos (citep:Tarantola2005,Kaipio2005) y la estimación de modelos predictivos por medio de Ridge o Lasso (citep:Hastie2009c). Por ejemplo, se pueden considerar regularizadores  como  penalizaciones en *norma 2* (=Ridge=, $\|\theta\|_2^2 =  \sum (\theta_i)^2$ ) o *norma 1* (=Lasso=, $\|\theta\|_1 = \sum |\theta_i|$ ).

** Formulación probabilística 

En términos probabilísticos esto correspondería a plantear un modelo
\begin{align}
\pi(\theta | y ) \propto \exp \left(  - \mathcal{J}(y, f_\theta(x))  \right) \, \exp \left(- R(\theta)  \right)\,.
\end{align}

Por ejemplo, considerar ~regresión Ridge~ implica considerar un modelo =Gaussiano=
para la =verosimilitud= y un modelo Gaussiano para la =previa=.

#+BEGIN_NOTES
Una variable aleatoria Gaussiana tiene conexiones interesantes con la ~descomposición espectral~ de una señal (descomposición en valores singulares y series de Fourier). Si pensamos que en un problema de regresión queremos estimar coeficientes. La solución sin restricciones nos puede dar algunos coeficientes con ~errores estándar muy altos~ y en consecuencia ~estadísticamente no significativos~ (alta varianza y centrados en cero). La regularización elimina la alta variabilidad (las frecuencia altas de una señal) y rápidamente centra los valores de aquellos valores alrededor del cero para tener una señal con una frecuencia mas /suave/. ¡La conexión la podemos trazar a los coeficientes de Fourier (citep:Fourier1878)!
#+END_NOTES

La solución de este problema de optimización se traduce en encontrar el punto
~máximo posterior~.

Ahora, el problema es que tanto para Ridge (previa Gaussiana) como para LASSO
(previa ~doble-exponencial~ o Laplace), la /moda/ --el punto que maximiza la posterior-- es muy
distinto de lo que nos darían simulaciones de ese modelo.

En el contexto Bayesiano nos interesaría poder utilizar una distribución previa
de la cual podamos extraer muestras donde algunos componentes son cero. Con este
propósito se han estudiado y propuesto previas de la familia ~horseshoe~
(presiento que es un modismo finlandés) citep:Piironen2017a.

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/previas-regularizacion.jpeg :exports results :results output graphics file
  ## Modelos de regularizacion --------------------------------
  modelos_files <- "modelos/compilados/regularizacion"
  ruta <- file.path("modelos/regularizacion/modelo-")

  compila_modelo <- function(modelo){
    modelo_name <- paste(ruta, modelo, ".stan",sep = "")
    cmdstan_model(modelo_name, dir = modelos_files)
  }

  genera_muestras <- function(modelo){
    modelo$sample(data = data.list, 
                  chains = 1, 
                  iter=5000, 
                  iter_warmup=500, 
                  seed=483892929, 
                  refresh=700)
  }

  data.list <- list(p = 2, sigma = 1)

  tibble(nombre = fct_inorder(c("normal", "laplace", "horseshoe"))) |>
    mutate(modelo = map(nombre, compila_modelo),
           ajuste = map(modelo, genera_muestras),
           muestras = map(ajuste, function(x){ as_draws_df(x$draws()) })) |>
    unnest(muestras) |>
    ggplot(aes(`theta[1]`, `theta[2]`)) +
    geom_point(size = 1, alpha = .2) +
    facet_wrap(~nombre) + sin_lineas + coord_equal() +
    xlim(-10, 10) + ylim(-10, 10) +
    ylab(expression(theta[2])) + xlab(expression(theta[1]))
#+end_src
#+caption: Distintas previas y efectos de regularización. 
#+RESULTS:
[[file:../images/previas-regularizacion.jpeg]]

** Regularización en regresión (diabetes)

Veamos lo siguiente para comparar los distintos modelos probabilísticos (Normal, Laplace, Horseshoe). 

#+begin_src R :exports none :results none
  ## Ejemplo regresion regularizada --------------------------------
  library(rstanarm)
  library(bayesplot)
  data <- read_csv("datos/diabetes.csv")
  # removing those observation rows with 0 in any of the variables
  for (i in 2:6) {
        data <- data[-which(data[, i] == 0), ]
  }
  # scale the covariates for easier comparison of coefficient posteriors
  for (i in 1:8) {
        data[i] <- scale(data[i])
  }
  # modify the data column names slightly for easier typing
  names(data)[7] <- "dpf"
  names(data) <- tolower(names(data))
  data$outcome <- factor(data$outcome)

  n=dim(data)[1]
  p=dim(data)[2]

  (reg_formula <- formula(paste("outcome ~", paste(names(data)[1:(p-1)], collapse = " + "))))

  model.normal <- stan_glm(reg_formula, data, family = binomial(link = "logit"))

  g1 <- plot(model.normal, "areas", prob = 0.95, prob_outer = 1) +
    geom_vline(xintercept = 0, lty = 2) + ggtitle("Normal")
#+end_src

#+HEADER: :width 1200 :height 400 :R-dev-args bg="transparent"
#+begin_src R :file images/comparacion-regularizacion-diabetes.jpeg :exports results :results output graphics file
    model.laplace <- stan_glm(reg_formula, data, family = binomial(link = "logit"),
                                prior = laplace())
    model.horseshoe <- stan_glm(reg_formula, data, family = binomial(link = "logit"),
                                prior = hs())

    g2 <- plot(model.laplace, "areas", prob = 0.95, prob_outer = 1) +
      geom_vline(xintercept = 0, lty = 2) + ggtitle("Laplace")
    g3 <- plot(model.horseshoe, "areas", prob = 0.95, prob_outer = 1) +
      geom_vline(xintercept = 0, lty = 2) + ggtitle("Horseshoe")

    g1 + g2 + g3
#+end_src
#+caption: Ajuste posterior bajo distinas previas. 
#+RESULTS:
[[file:../images/comparacion-regularizacion-diabetes.jpeg]]

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/dispersion-regularizacion.jpeg :exports results :results output graphics file
  mcmc_scatter(model.horseshoe,
             pars = c("pregnancies", "skinthickness"),
             np   = nuts_params(model.horseshoe),
             alpha = 0.2)
#+end_src
#+caption: Efecto de la regularización en un par de coeficientes. 
#+RESULTS:
[[file:../images/dispersion-regularizacion.jpeg]]

** Regularización en regresión (carros)

Notemos como el modelo tiene dos zonas de alta probabilidad. 

#+HEADER: :width 900 :height 500 :R-dev-args bg="transparent"
#+begin_src R :file images/dispersion-mtcars.jpeg :exports results :results output graphics file
  ## Ejemplo mtcars ------------------------------------
  fit <- stan_glm(
    mpg ~ ., data = mtcars,
    iter = 1000, refresh = 0,
    # this combo of prior and adapt_delta should lead to some divergences
    prior = hs(),
    adapt_delta = 0.9
  )

  posterior <- as.array(fit)
  np <- nuts_params(fit)

  # mcmc_scatter with divergences highlighted
  mcmc_scatter(posterior, pars = c("wt", "sigma"), np = np, alpha = .3)
#+end_src
#+caption: Efecto de regularización en dos parámetros de un modelo. 
#+RESULTS:
[[file:../images/dispersion-mtcars.jpeg]]

# * Referencias                                                         :latex:

# bibliographystyle:abbrvnat
# bibliography:references.bib

